{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.linear_model import LinearRegression # explicit class import from module\n",
    "from sklearn.linear_model import LogisticRegression # explicit class import from module\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier #we know where this object comes from\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "warnings.filterwarnings('ignore') # Code for stopping warnings (deprecation warning, etc.)\n",
    "pd.set_option('display.max_columns', None) # Code for showin g all columns in the dateset, withoud '...' in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>age</th>\n",
       "      <th>attrition</th>\n",
       "      <th>daily_rate</th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>education</th>\n",
       "      <th>environment_satisfaction</th>\n",
       "      <th>gender</th>\n",
       "      <th>hourly_rate</th>\n",
       "      <th>job_involvement</th>\n",
       "      <th>job_level</th>\n",
       "      <th>job_satisfaction</th>\n",
       "      <th>monthly_income</th>\n",
       "      <th>monthly_rate</th>\n",
       "      <th>num_companies_worked</th>\n",
       "      <th>over_time</th>\n",
       "      <th>percent_salary_hike</th>\n",
       "      <th>performance_rating</th>\n",
       "      <th>relationship_satisfaction</th>\n",
       "      <th>stock_option_level</th>\n",
       "      <th>total_working_years</th>\n",
       "      <th>training_times_last_year</th>\n",
       "      <th>work_life_balance</th>\n",
       "      <th>years_at_company</th>\n",
       "      <th>years_in_current_role</th>\n",
       "      <th>years_since_last_promotion</th>\n",
       "      <th>years_with_curr_manager</th>\n",
       "      <th>business_travel_Non-Travel</th>\n",
       "      <th>business_travel_Travel_Frequently</th>\n",
       "      <th>business_travel_Travel_Rarely</th>\n",
       "      <th>department_Human Resources</th>\n",
       "      <th>department_Research &amp; Development</th>\n",
       "      <th>department_Sales</th>\n",
       "      <th>education_field_Human Resources</th>\n",
       "      <th>education_field_Life Sciences</th>\n",
       "      <th>education_field_Marketing</th>\n",
       "      <th>education_field_Medical</th>\n",
       "      <th>education_field_Other</th>\n",
       "      <th>education_field_Technical Degree</th>\n",
       "      <th>job_role_Healthcare Representative</th>\n",
       "      <th>job_role_Human Resources</th>\n",
       "      <th>job_role_Laboratory Technician</th>\n",
       "      <th>job_role_Manager</th>\n",
       "      <th>job_role_Manufacturing Director</th>\n",
       "      <th>job_role_Research Director</th>\n",
       "      <th>job_role_Research Scientist</th>\n",
       "      <th>job_role_Sales Executive</th>\n",
       "      <th>job_role_Sales Representative</th>\n",
       "      <th>marital_status_Divorced</th>\n",
       "      <th>marital_status_Married</th>\n",
       "      <th>marital_status_Single</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>456</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.340456</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.972222</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.240007</td>\n",
       "      <td>-0.694698</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>485</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.653846</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.861111</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.359003</td>\n",
       "      <td>-0.394561</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.888889</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1049</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.029915</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.805556</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.482582</td>\n",
       "      <td>-0.461706</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1102</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122507</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.477081</td>\n",
       "      <td>0.681382</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>806</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.159544</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.178951</td>\n",
       "      <td>0.834154</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.222222</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id       age  attrition  daily_rate  distance_from_home  \\\n",
       "0          456 -0.500000          0   -0.340456           -0.166667   \n",
       "1          485 -0.250000          1   -0.653846           -0.166667   \n",
       "2         1049  0.750000          0   -0.029915            1.416667   \n",
       "3         1102 -0.666667          0    0.122507            0.666667   \n",
       "4          806 -0.500000          0    0.159544           -0.500000   \n",
       "\n",
       "   education  environment_satisfaction  gender  hourly_rate  job_involvement  \\\n",
       "0          3                         4       1    -0.972222                2   \n",
       "1          3                         4       1    -0.861111                3   \n",
       "2          4                         2       0    -0.805556                3   \n",
       "3          2                         1       0    -0.416667                3   \n",
       "4          3                         4       0    -0.750000                1   \n",
       "\n",
       "   job_level  job_satisfaction  monthly_income  monthly_rate  \\\n",
       "0          2                 3        0.240007     -0.694698   \n",
       "1          1                 3       -0.359003     -0.394561   \n",
       "2          1                 2       -0.482582     -0.461706   \n",
       "3          1                 3       -0.477081      0.681382   \n",
       "4          1                 3       -0.178951      0.834154   \n",
       "\n",
       "   num_companies_worked  over_time  percent_salary_hike  performance_rating  \\\n",
       "0             -0.333333          0            -0.166667                   3   \n",
       "1             -0.333333          1            -0.166667                   3   \n",
       "2             -0.333333          0             0.333333                   3   \n",
       "3             -0.333333          0             0.333333                   3   \n",
       "4              0.333333          0             1.166667                   4   \n",
       "\n",
       "   relationship_satisfaction  stock_option_level  total_working_years  \\\n",
       "0                          3                   3             0.111111   \n",
       "1                          2                   0            -0.888889   \n",
       "2                          1                   0            -0.333333   \n",
       "3                          4                   1            -0.555556   \n",
       "4                          3                   2            -0.222222   \n",
       "\n",
       "   training_times_last_year  work_life_balance  years_at_company  \\\n",
       "0                      -1.0                  3          0.833333   \n",
       "1                      -1.0                  3         -0.666667   \n",
       "2                       0.0                  3          0.166667   \n",
       "3                       2.0                  2         -0.166667   \n",
       "4                      -1.0                  3         -0.500000   \n",
       "\n",
       "   years_in_current_role  years_since_last_promotion  years_with_curr_manager  \\\n",
       "0                    1.2                    0.000000                     -0.2   \n",
       "1                   -0.6                   -0.333333                     -0.6   \n",
       "2                    0.0                   -0.333333                      0.2   \n",
       "3                   -0.2                    0.333333                     -0.2   \n",
       "4                   -0.2                   -0.333333                     -0.2   \n",
       "\n",
       "   business_travel_Non-Travel  business_travel_Travel_Frequently  \\\n",
       "0                           0                                  0   \n",
       "1                           0                                  0   \n",
       "2                           0                                  0   \n",
       "3                           0                                  0   \n",
       "4                           0                                  0   \n",
       "\n",
       "   business_travel_Travel_Rarely  department_Human Resources  \\\n",
       "0                              1                           0   \n",
       "1                              1                           0   \n",
       "2                              1                           1   \n",
       "3                              1                           0   \n",
       "4                              1                           0   \n",
       "\n",
       "   department_Research & Development  department_Sales  \\\n",
       "0                                  0                 1   \n",
       "1                                  0                 1   \n",
       "2                                  0                 0   \n",
       "3                                  1                 0   \n",
       "4                                  1                 0   \n",
       "\n",
       "   education_field_Human Resources  education_field_Life Sciences  \\\n",
       "0                                0                              0   \n",
       "1                                0                              0   \n",
       "2                                0                              0   \n",
       "3                                0                              1   \n",
       "4                                0                              1   \n",
       "\n",
       "   education_field_Marketing  education_field_Medical  education_field_Other  \\\n",
       "0                          1                        0                      0   \n",
       "1                          1                        0                      0   \n",
       "2                          0                        1                      0   \n",
       "3                          0                        0                      0   \n",
       "4                          0                        0                      0   \n",
       "\n",
       "   education_field_Technical Degree  job_role_Healthcare Representative  \\\n",
       "0                                 0                                   0   \n",
       "1                                 0                                   0   \n",
       "2                                 0                                   0   \n",
       "3                                 0                                   0   \n",
       "4                                 0                                   0   \n",
       "\n",
       "   job_role_Human Resources  job_role_Laboratory Technician  job_role_Manager  \\\n",
       "0                         0                               0                 0   \n",
       "1                         0                               0                 0   \n",
       "2                         1                               0                 0   \n",
       "3                         0                               1                 0   \n",
       "4                         0                               1                 0   \n",
       "\n",
       "   job_role_Manufacturing Director  job_role_Research Director  \\\n",
       "0                                0                           0   \n",
       "1                                0                           0   \n",
       "2                                0                           0   \n",
       "3                                0                           0   \n",
       "4                                0                           0   \n",
       "\n",
       "   job_role_Research Scientist  job_role_Sales Executive  \\\n",
       "0                            0                         1   \n",
       "1                            0                         0   \n",
       "2                            0                         0   \n",
       "3                            0                         0   \n",
       "4                            0                         0   \n",
       "\n",
       "   job_role_Sales Representative  marital_status_Divorced  \\\n",
       "0                              0                        1   \n",
       "1                              1                        0   \n",
       "2                              0                        0   \n",
       "3                              0                        1   \n",
       "4                              0                        0   \n",
       "\n",
       "   marital_status_Married  marital_status_Single  \n",
       "0                       0                      0  \n",
       "1                       0                      1  \n",
       "2                       0                      1  \n",
       "3                       0                      0  \n",
       "4                       1                      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people = pd.read_csv(\"../raw_data/people_train.csv\")\n",
    "people.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = people.drop(columns = ['employee_id','attrition'])\n",
    "y = people['attrition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X,y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=0)\n",
    "X_train_smote, y_train_smote = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before SMOTE : Counter({0: 646, 1: 125})\n",
      "after SMOTE : Counter({0: 646, 1: 646})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print('before SMOTE :' , Counter(y_train))\n",
    "print('after SMOTE :' , Counter(y_train_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8573271889400921\n",
      "f1:  0.24176576935197622\n",
      "recall:  0.11199999999999999\n"
     ]
    }
   ],
   "source": [
    "#sem smote\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "sacc = cross_val_score(model, X_train, y_train, scoring='accuracy')\n",
    "sf1 = cross_val_score(model, X_train, y_train, scoring='f1')\n",
    "sre = cross_val_score(model, X_train, y_train, scoring='recall')\n",
    "print('accuracy: ',sacc.mean())\n",
    "print('f1: ',sf1.mean())\n",
    "print('recall: ',sre.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9358534614348567\n",
      "f1:  0.9327520048194243\n",
      "recall:  0.9225044722719142\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=115)\n",
    "sacc = cross_val_score(model, X_train_smote, y_train_smote, scoring='accuracy')\n",
    "sf1 = cross_val_score(model, X_train_smote, y_train_smote, scoring='f1')\n",
    "sre = cross_val_score(model, X_train_smote, y_train_smote, scoring='recall')\n",
    "print('accuracy: ',sacc.mean())\n",
    "print('f1: ',sf1.mean())\n",
    "print('recall: ',sre.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7131782945736435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.70      0.80       216\n",
      "           1       0.33      0.76      0.46        42\n",
      "\n",
      "    accuracy                           0.71       258\n",
      "   macro avg       0.64      0.73      0.63       258\n",
      "weighted avg       0.84      0.71      0.75       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testando treshold\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "threshold = 0.3\n",
    "predicted_proba = model.predict_proba(X_val)\n",
    "predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "accuracy = accuracy_score(y_val, predicted)\n",
    "print(accuracy)\n",
    "print(classification_report(y_val, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predrandf = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       216\n",
      "           1       0.16      1.00      0.28        42\n",
      "\n",
      "    accuracy                           0.16       258\n",
      "   macro avg       0.08      0.50      0.14       258\n",
      "weighted avg       0.03      0.16      0.05       258\n",
      "\n",
      "0.01               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.02       216\n",
      "           1       0.16      1.00      0.28        42\n",
      "\n",
      "    accuracy                           0.17       258\n",
      "   macro avg       0.58      0.50      0.15       258\n",
      "weighted avg       0.86      0.17      0.06       258\n",
      "\n",
      "0.02               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.02       216\n",
      "           1       0.16      1.00      0.28        42\n",
      "\n",
      "    accuracy                           0.17       258\n",
      "   macro avg       0.58      0.50      0.15       258\n",
      "weighted avg       0.86      0.17      0.06       258\n",
      "\n",
      "0.03               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.03       216\n",
      "           1       0.16      1.00      0.28        42\n",
      "\n",
      "    accuracy                           0.17       258\n",
      "   macro avg       0.58      0.51      0.16       258\n",
      "weighted avg       0.86      0.17      0.07       258\n",
      "\n",
      "0.04               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.05       216\n",
      "           1       0.17      1.00      0.29        42\n",
      "\n",
      "    accuracy                           0.19       258\n",
      "   macro avg       0.58      0.51      0.17       258\n",
      "weighted avg       0.86      0.19      0.09       258\n",
      "\n",
      "0.05               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.05      0.09       216\n",
      "           1       0.17      1.00      0.29        42\n",
      "\n",
      "    accuracy                           0.20       258\n",
      "   macro avg       0.58      0.52      0.19       258\n",
      "weighted avg       0.86      0.20      0.12       258\n",
      "\n",
      "0.06               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.06      0.12       216\n",
      "           1       0.17      1.00      0.29        42\n",
      "\n",
      "    accuracy                           0.22       258\n",
      "   macro avg       0.59      0.53      0.21       258\n",
      "weighted avg       0.87      0.22      0.15       258\n",
      "\n",
      "0.07               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.10      0.18       216\n",
      "           1       0.18      1.00      0.30        42\n",
      "\n",
      "    accuracy                           0.25       258\n",
      "   macro avg       0.59      0.55      0.24       258\n",
      "weighted avg       0.87      0.25      0.20       258\n",
      "\n",
      "0.08               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.12      0.22       216\n",
      "           1       0.18      1.00      0.31        42\n",
      "\n",
      "    accuracy                           0.27       258\n",
      "   macro avg       0.59      0.56      0.26       258\n",
      "weighted avg       0.87      0.27      0.24       258\n",
      "\n",
      "0.09               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.15      0.27       216\n",
      "           1       0.19      1.00      0.31        42\n",
      "\n",
      "    accuracy                           0.29       258\n",
      "   macro avg       0.59      0.58      0.29       258\n",
      "weighted avg       0.87      0.29      0.27       258\n",
      "\n",
      "0.1               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.16      0.28       216\n",
      "           1       0.19      1.00      0.32        42\n",
      "\n",
      "    accuracy                           0.30       258\n",
      "   macro avg       0.59      0.58      0.30       258\n",
      "weighted avg       0.87      0.30      0.29       258\n",
      "\n",
      "0.11               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.19      0.31       216\n",
      "           1       0.19      1.00      0.32        42\n",
      "\n",
      "    accuracy                           0.32       258\n",
      "   macro avg       0.60      0.59      0.32       258\n",
      "weighted avg       0.87      0.32      0.31       258\n",
      "\n",
      "0.12               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.23      0.37       216\n",
      "           1       0.20      1.00      0.33        42\n",
      "\n",
      "    accuracy                           0.35       258\n",
      "   macro avg       0.60      0.61      0.35       258\n",
      "weighted avg       0.87      0.35      0.36       258\n",
      "\n",
      "0.13               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.26      0.41       216\n",
      "           1       0.20      0.95      0.33        42\n",
      "\n",
      "    accuracy                           0.37       258\n",
      "   macro avg       0.58      0.61      0.37       258\n",
      "weighted avg       0.84      0.37      0.40       258\n",
      "\n",
      "0.14               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.30      0.45       216\n",
      "           1       0.20      0.93      0.33        42\n",
      "\n",
      "    accuracy                           0.40       258\n",
      "   macro avg       0.58      0.61      0.39       258\n",
      "weighted avg       0.83      0.40      0.43       258\n",
      "\n",
      "0.15               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.32      0.48       216\n",
      "           1       0.21      0.93      0.34        42\n",
      "\n",
      "    accuracy                           0.42       258\n",
      "   macro avg       0.58      0.62      0.41       258\n",
      "weighted avg       0.84      0.42      0.46       258\n",
      "\n",
      "0.16               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.34      0.51       216\n",
      "           1       0.22      0.93      0.35        42\n",
      "\n",
      "    accuracy                           0.44       258\n",
      "   macro avg       0.59      0.64      0.43       258\n",
      "weighted avg       0.84      0.44      0.48       258\n",
      "\n",
      "0.17               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.37      0.53       216\n",
      "           1       0.22      0.93      0.36        42\n",
      "\n",
      "    accuracy                           0.46       258\n",
      "   macro avg       0.59      0.65      0.44       258\n",
      "weighted avg       0.84      0.46      0.50       258\n",
      "\n",
      "0.18               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.38      0.55       216\n",
      "           1       0.23      0.93      0.36        42\n",
      "\n",
      "    accuracy                           0.47       258\n",
      "   macro avg       0.60      0.66      0.46       258\n",
      "weighted avg       0.84      0.47      0.52       258\n",
      "\n",
      "0.19               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.41      0.58       216\n",
      "           1       0.23      0.90      0.37        42\n",
      "\n",
      "    accuracy                           0.49       258\n",
      "   macro avg       0.59      0.66      0.47       258\n",
      "weighted avg       0.84      0.49      0.54       258\n",
      "\n",
      "0.2               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.45      0.61       216\n",
      "           1       0.24      0.88      0.37        42\n",
      "\n",
      "    accuracy                           0.52       258\n",
      "   macro avg       0.59      0.67      0.49       258\n",
      "weighted avg       0.83      0.52      0.57       258\n",
      "\n",
      "0.21               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.51      0.66       216\n",
      "           1       0.25      0.86      0.39        42\n",
      "\n",
      "    accuracy                           0.57       258\n",
      "   macro avg       0.60      0.68      0.53       258\n",
      "weighted avg       0.84      0.57      0.62       258\n",
      "\n",
      "0.22               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.55      0.69       216\n",
      "           1       0.26      0.83      0.40        42\n",
      "\n",
      "    accuracy                           0.59       258\n",
      "   macro avg       0.60      0.69      0.55       258\n",
      "weighted avg       0.83      0.59      0.64       258\n",
      "\n",
      "0.23               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.56      0.71       216\n",
      "           1       0.27      0.83      0.41        42\n",
      "\n",
      "    accuracy                           0.61       258\n",
      "   macro avg       0.61      0.70      0.56       258\n",
      "weighted avg       0.84      0.61      0.66       258\n",
      "\n",
      "0.24               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.59      0.73       216\n",
      "           1       0.28      0.83      0.42        42\n",
      "\n",
      "    accuracy                           0.63       258\n",
      "   macro avg       0.62      0.71      0.58       258\n",
      "weighted avg       0.84      0.63      0.68       258\n",
      "\n",
      "0.25               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.62      0.75       216\n",
      "           1       0.29      0.81      0.43        42\n",
      "\n",
      "    accuracy                           0.65       258\n",
      "   macro avg       0.62      0.71      0.59       258\n",
      "weighted avg       0.84      0.65      0.69       258\n",
      "\n",
      "0.26               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.62      0.75       216\n",
      "           1       0.29      0.81      0.43        42\n",
      "\n",
      "    accuracy                           0.65       258\n",
      "   macro avg       0.62      0.71      0.59       258\n",
      "weighted avg       0.84      0.65      0.70       258\n",
      "\n",
      "0.27               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.67      0.78       216\n",
      "           1       0.32      0.81      0.46        42\n",
      "\n",
      "    accuracy                           0.69       258\n",
      "   macro avg       0.63      0.74      0.62       258\n",
      "weighted avg       0.85      0.69      0.73       258\n",
      "\n",
      "0.28               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.68      0.79       216\n",
      "           1       0.33      0.81      0.47        42\n",
      "\n",
      "    accuracy                           0.70       258\n",
      "   macro avg       0.64      0.74      0.63       258\n",
      "weighted avg       0.85      0.70      0.74       258\n",
      "\n",
      "0.29               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.68      0.79       216\n",
      "           1       0.33      0.81      0.47        42\n",
      "\n",
      "    accuracy                           0.70       258\n",
      "   macro avg       0.64      0.75      0.63       258\n",
      "weighted avg       0.85      0.70      0.74       258\n",
      "\n",
      "0.3               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.70      0.80       216\n",
      "           1       0.33      0.76      0.46        42\n",
      "\n",
      "    accuracy                           0.71       258\n",
      "   macro avg       0.64      0.73      0.63       258\n",
      "weighted avg       0.84      0.71      0.75       258\n",
      "\n",
      "0.31               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.71      0.81       216\n",
      "           1       0.34      0.76      0.47        42\n",
      "\n",
      "    accuracy                           0.72       258\n",
      "   macro avg       0.64      0.74      0.64       258\n",
      "weighted avg       0.84      0.72      0.75       258\n",
      "\n",
      "0.32               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.73      0.82       216\n",
      "           1       0.33      0.69      0.45        42\n",
      "\n",
      "    accuracy                           0.72       258\n",
      "   macro avg       0.63      0.71      0.63       258\n",
      "weighted avg       0.83      0.72      0.76       258\n",
      "\n",
      "0.33               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.76      0.83       216\n",
      "           1       0.36      0.69      0.47        42\n",
      "\n",
      "    accuracy                           0.75       258\n",
      "   macro avg       0.64      0.72      0.65       258\n",
      "weighted avg       0.83      0.75      0.78       258\n",
      "\n",
      "0.34               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.78      0.84       216\n",
      "           1       0.36      0.64      0.46        42\n",
      "\n",
      "    accuracy                           0.76       258\n",
      "   macro avg       0.64      0.71      0.65       258\n",
      "weighted avg       0.83      0.76      0.78       258\n",
      "\n",
      "0.35000000000000003               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86       216\n",
      "           1       0.38      0.62      0.47        42\n",
      "\n",
      "    accuracy                           0.78       258\n",
      "   macro avg       0.65      0.71      0.66       258\n",
      "weighted avg       0.83      0.78      0.79       258\n",
      "\n",
      "0.36               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86       216\n",
      "           1       0.39      0.62      0.48        42\n",
      "\n",
      "    accuracy                           0.78       258\n",
      "   macro avg       0.66      0.72      0.67       258\n",
      "weighted avg       0.83      0.78      0.80       258\n",
      "\n",
      "0.37               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87       216\n",
      "           1       0.41      0.62      0.49        42\n",
      "\n",
      "    accuracy                           0.79       258\n",
      "   macro avg       0.66      0.72      0.68       258\n",
      "weighted avg       0.83      0.79      0.81       258\n",
      "\n",
      "0.38               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.87       216\n",
      "           1       0.38      0.52      0.44        42\n",
      "\n",
      "    accuracy                           0.78       258\n",
      "   macro avg       0.64      0.68      0.65       258\n",
      "weighted avg       0.82      0.78      0.80       258\n",
      "\n",
      "0.39               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88       216\n",
      "           1       0.41      0.52      0.46        42\n",
      "\n",
      "    accuracy                           0.80       258\n",
      "   macro avg       0.65      0.69      0.67       258\n",
      "weighted avg       0.82      0.80      0.81       258\n",
      "\n",
      "0.4               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88       216\n",
      "           1       0.40      0.48      0.43        42\n",
      "\n",
      "    accuracy                           0.80       258\n",
      "   macro avg       0.65      0.67      0.66       258\n",
      "weighted avg       0.81      0.80      0.81       258\n",
      "\n",
      "0.41000000000000003               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       216\n",
      "           1       0.43      0.48      0.45        42\n",
      "\n",
      "    accuracy                           0.81       258\n",
      "   macro avg       0.66      0.68      0.67       258\n",
      "weighted avg       0.82      0.81      0.81       258\n",
      "\n",
      "0.42               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88       216\n",
      "           1       0.41      0.43      0.42        42\n",
      "\n",
      "    accuracy                           0.81       258\n",
      "   macro avg       0.65      0.65      0.65       258\n",
      "weighted avg       0.81      0.81      0.81       258\n",
      "\n",
      "0.43               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       216\n",
      "           1       0.38      0.38      0.38        42\n",
      "\n",
      "    accuracy                           0.80       258\n",
      "   macro avg       0.63      0.63      0.63       258\n",
      "weighted avg       0.80      0.80      0.80       258\n",
      "\n",
      "0.44               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89       216\n",
      "           1       0.41      0.38      0.40        42\n",
      "\n",
      "    accuracy                           0.81       258\n",
      "   macro avg       0.65      0.64      0.64       258\n",
      "weighted avg       0.80      0.81      0.81       258\n",
      "\n",
      "0.45               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       216\n",
      "           1       0.44      0.38      0.41        42\n",
      "\n",
      "    accuracy                           0.82       258\n",
      "   macro avg       0.66      0.64      0.65       258\n",
      "weighted avg       0.81      0.82      0.82       258\n",
      "\n",
      "0.46               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       216\n",
      "           1       0.42      0.33      0.37        42\n",
      "\n",
      "    accuracy                           0.82       258\n",
      "   macro avg       0.65      0.62      0.63       258\n",
      "weighted avg       0.80      0.82      0.81       258\n",
      "\n",
      "0.47000000000000003               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       216\n",
      "           1       0.45      0.33      0.38        42\n",
      "\n",
      "    accuracy                           0.83       258\n",
      "   macro avg       0.66      0.63      0.64       258\n",
      "weighted avg       0.81      0.83      0.81       258\n",
      "\n",
      "0.48               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90       216\n",
      "           1       0.48      0.33      0.39        42\n",
      "\n",
      "    accuracy                           0.83       258\n",
      "   macro avg       0.68      0.63      0.65       258\n",
      "weighted avg       0.81      0.83      0.82       258\n",
      "\n",
      "0.49               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90       216\n",
      "           1       0.46      0.31      0.37        42\n",
      "\n",
      "    accuracy                           0.83       258\n",
      "   macro avg       0.67      0.62      0.64       258\n",
      "weighted avg       0.81      0.83      0.82       258\n",
      "\n",
      "0.5               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91       216\n",
      "           1       0.50      0.31      0.38        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.69      0.62      0.64       258\n",
      "weighted avg       0.81      0.84      0.82       258\n",
      "\n",
      "0.51               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90       216\n",
      "           1       0.48      0.29      0.36        42\n",
      "\n",
      "    accuracy                           0.83       258\n",
      "   macro avg       0.68      0.61      0.63       258\n",
      "weighted avg       0.81      0.83      0.82       258\n",
      "\n",
      "0.52               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.91       216\n",
      "           1       0.50      0.29      0.36        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.69      0.62      0.64       258\n",
      "weighted avg       0.81      0.84      0.82       258\n",
      "\n",
      "0.53               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91       216\n",
      "           1       0.52      0.29      0.37        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.70      0.62      0.64       258\n",
      "weighted avg       0.82      0.84      0.82       258\n",
      "\n",
      "0.54               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       216\n",
      "           1       0.57      0.29      0.38        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.72      0.62      0.65       258\n",
      "weighted avg       0.82      0.85      0.83       258\n",
      "\n",
      "0.55               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.92       216\n",
      "           1       0.60      0.29      0.39        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.74      0.62      0.65       258\n",
      "weighted avg       0.83      0.85      0.83       258\n",
      "\n",
      "0.56               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92       216\n",
      "           1       0.65      0.26      0.37        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.76      0.62      0.65       258\n",
      "weighted avg       0.83      0.86      0.83       258\n",
      "\n",
      "0.5700000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92       216\n",
      "           1       0.62      0.24      0.34        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.75      0.61      0.63       258\n",
      "weighted avg       0.83      0.85      0.82       258\n",
      "\n",
      "0.58               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91       216\n",
      "           1       0.57      0.19      0.29        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.72      0.58      0.60       258\n",
      "weighted avg       0.81      0.84      0.81       258\n",
      "\n",
      "0.59               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.92       216\n",
      "           1       0.62      0.19      0.29        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.74      0.58      0.60       258\n",
      "weighted avg       0.82      0.85      0.81       258\n",
      "\n",
      "0.6               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.98      0.91       216\n",
      "           1       0.55      0.14      0.23        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.70      0.56      0.57       258\n",
      "weighted avg       0.80      0.84      0.80       258\n",
      "\n",
      "0.61               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.98      0.91       216\n",
      "           1       0.50      0.12      0.19        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.68      0.55      0.55       258\n",
      "weighted avg       0.79      0.84      0.79       258\n",
      "\n",
      "0.62               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.92       216\n",
      "           1       0.71      0.12      0.20        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.78      0.55      0.56       258\n",
      "weighted avg       0.83      0.85      0.80       258\n",
      "\n",
      "0.63               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.92       216\n",
      "           1       0.71      0.12      0.20        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.78      0.55      0.56       258\n",
      "weighted avg       0.83      0.85      0.80       258\n",
      "\n",
      "0.64               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       216\n",
      "           1       0.80      0.10      0.17        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.82      0.55      0.54       258\n",
      "weighted avg       0.84      0.85      0.80       258\n",
      "\n",
      "0.65               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       216\n",
      "           1       0.80      0.10      0.17        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.82      0.55      0.54       258\n",
      "weighted avg       0.84      0.85      0.80       258\n",
      "\n",
      "0.66               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       216\n",
      "           1       0.80      0.10      0.17        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.82      0.55      0.54       258\n",
      "weighted avg       0.84      0.85      0.80       258\n",
      "\n",
      "0.67               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       216\n",
      "           1       0.80      0.10      0.17        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.82      0.55      0.54       258\n",
      "weighted avg       0.84      0.85      0.80       258\n",
      "\n",
      "0.68               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       216\n",
      "           1       0.80      0.10      0.17        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.82      0.55      0.54       258\n",
      "weighted avg       0.84      0.85      0.80       258\n",
      "\n",
      "0.6900000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       216\n",
      "           1       0.80      0.10      0.17        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.82      0.55      0.54       258\n",
      "weighted avg       0.84      0.85      0.80       258\n",
      "\n",
      "0.7000000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       216\n",
      "           1       0.80      0.10      0.17        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.82      0.55      0.54       258\n",
      "weighted avg       0.84      0.85      0.80       258\n",
      "\n",
      "0.71               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       216\n",
      "           1       0.80      0.10      0.17        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.82      0.55      0.54       258\n",
      "weighted avg       0.84      0.85      0.80       258\n",
      "\n",
      "0.72               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       216\n",
      "           1       0.80      0.10      0.17        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.82      0.55      0.54       258\n",
      "weighted avg       0.84      0.85      0.80       258\n",
      "\n",
      "0.73               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.91       216\n",
      "           1       0.75      0.07      0.13        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.80      0.53      0.52       258\n",
      "weighted avg       0.83      0.84      0.79       258\n",
      "\n",
      "0.74               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.92       216\n",
      "           1       1.00      0.05      0.09        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.92      0.52      0.50       258\n",
      "weighted avg       0.87      0.84      0.78       258\n",
      "\n",
      "0.75               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.92       216\n",
      "           1       1.00      0.05      0.09        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.92      0.52      0.50       258\n",
      "weighted avg       0.87      0.84      0.78       258\n",
      "\n",
      "0.76               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.92       216\n",
      "           1       1.00      0.05      0.09        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.92      0.52      0.50       258\n",
      "weighted avg       0.87      0.84      0.78       258\n",
      "\n",
      "0.77               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       1.00      0.02      0.05        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.92      0.51      0.48       258\n",
      "weighted avg       0.87      0.84      0.77       258\n",
      "\n",
      "0.78               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.79               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.8               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.81               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.8200000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.8300000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.84               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.85               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.86               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.87               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.88               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.89               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.9               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.91               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.92               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.93               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.9400000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.9500000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.96               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.97               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.98               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.99               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for threshold in np.arange(0,1,0.01):\n",
    "    predicted_proba = model.predict_proba(X_val)\n",
    "    predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "    accuracy = accuracy_score(y_val, predicted)\n",
    "    print(threshold, classification_report(y_val, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [2,4]\n",
    "min_samples_split = [2,5]\n",
    "min_samples_leaf = [2,5]\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'max_features': max_features,\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "        'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:   28.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(n_estimators=115),\n",
       "             param_grid={'bootstrap': [True, False], 'max_depth': [2, 4],\n",
       "                         'max_features': ['auto', 'sqrt'],\n",
       "                         'min_samples_leaf': [2, 5],\n",
       "                         'min_samples_split': [2, 5]},\n",
       "             scoring='recall', verbose=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rGRID = GridSearchCV(model, param_grid = grid, scoring = 'recall', verbose = 1)\n",
    "rGRID.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rGRID.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7751937984496124"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rGRID.best_estimator_.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rGRID.best_estimator_.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       196\n",
      "           1       0.55      0.37      0.44        62\n",
      "\n",
      "    accuracy                           0.78       258\n",
      "   macro avg       0.68      0.64      0.65       258\n",
      "weighted avg       0.75      0.78      0.76       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(rGRID.best_estimator_ , X_val, y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44680851063829785"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "21/(21+26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=4, max_features='sqrt', min_samples_leaf=2,\n",
       "                       n_estimators=115)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rGRID.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7751937984496124"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rGRID.best_estimator_.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8887043189368772\n",
      "f1:  0.8493707087503536\n",
      "recall:  0.8403220035778176\n"
     ]
    }
   ],
   "source": [
    "lgmodel = LogisticRegression(random_state=0)\n",
    "lgmodel.fit(X_train_smote, y_train_smote)\n",
    "sacc = cross_val_score(lgmodel, X_train_smote, y_train_smote, scoring='accuracy')\n",
    "sf1 = cross_val_score(lgmodel, X_train_smote, y_train_smote, scoring='f1')\n",
    "sre = cross_val_score(lgmodel, X_train_smote, y_train_smote, scoring='recall')\n",
    "print('accuracy: ',sacc.mean())\n",
    "print('f1: ',sf1.mean())\n",
    "print('recall: ',sre.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predlog = lgmodel.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       216\n",
      "           1       0.16      1.00      0.28        42\n",
      "\n",
      "    accuracy                           0.16       258\n",
      "   macro avg       0.08      0.50      0.14       258\n",
      "weighted avg       0.03      0.16      0.05       258\n",
      "\n",
      "0.01               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.14      0.25       216\n",
      "           1       0.18      0.98      0.31        42\n",
      "\n",
      "    accuracy                           0.28       258\n",
      "   macro avg       0.58      0.56      0.28       258\n",
      "weighted avg       0.84      0.28      0.26       258\n",
      "\n",
      "0.02               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.25      0.39       216\n",
      "           1       0.19      0.93      0.32        42\n",
      "\n",
      "    accuracy                           0.36       258\n",
      "   macro avg       0.57      0.59      0.35       258\n",
      "weighted avg       0.82      0.36      0.38       258\n",
      "\n",
      "0.03               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.33      0.49       216\n",
      "           1       0.21      0.93      0.35        42\n",
      "\n",
      "    accuracy                           0.43       258\n",
      "   macro avg       0.59      0.63      0.42       258\n",
      "weighted avg       0.84      0.43      0.47       258\n",
      "\n",
      "0.04               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.37      0.53       216\n",
      "           1       0.22      0.93      0.36        42\n",
      "\n",
      "    accuracy                           0.46       258\n",
      "   macro avg       0.59      0.65      0.44       258\n",
      "weighted avg       0.84      0.46      0.50       258\n",
      "\n",
      "0.05               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.40      0.56       216\n",
      "           1       0.23      0.93      0.37        42\n",
      "\n",
      "    accuracy                           0.48       258\n",
      "   macro avg       0.60      0.66      0.47       258\n",
      "weighted avg       0.85      0.48      0.53       258\n",
      "\n",
      "0.06               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.43      0.60       216\n",
      "           1       0.24      0.93      0.38        42\n",
      "\n",
      "    accuracy                           0.51       258\n",
      "   macro avg       0.60      0.68      0.49       258\n",
      "weighted avg       0.85      0.51      0.56       258\n",
      "\n",
      "0.07               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.46      0.63       216\n",
      "           1       0.25      0.93      0.40        42\n",
      "\n",
      "    accuracy                           0.54       258\n",
      "   macro avg       0.61      0.70      0.51       258\n",
      "weighted avg       0.85      0.54      0.59       258\n",
      "\n",
      "0.08               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.49      0.65       216\n",
      "           1       0.26      0.93      0.41        42\n",
      "\n",
      "    accuracy                           0.56       258\n",
      "   macro avg       0.62      0.71      0.53       258\n",
      "weighted avg       0.86      0.56      0.61       258\n",
      "\n",
      "0.09               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.54      0.69       216\n",
      "           1       0.28      0.93      0.43        42\n",
      "\n",
      "    accuracy                           0.60       258\n",
      "   macro avg       0.63      0.73      0.56       258\n",
      "weighted avg       0.86      0.60      0.65       258\n",
      "\n",
      "0.1               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.56      0.71       216\n",
      "           1       0.28      0.90      0.43        42\n",
      "\n",
      "    accuracy                           0.61       258\n",
      "   macro avg       0.63      0.73      0.57       258\n",
      "weighted avg       0.86      0.61      0.66       258\n",
      "\n",
      "0.11               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.58      0.72       216\n",
      "           1       0.29      0.90      0.44        42\n",
      "\n",
      "    accuracy                           0.63       258\n",
      "   macro avg       0.63      0.74      0.58       258\n",
      "weighted avg       0.86      0.63      0.68       258\n",
      "\n",
      "0.12               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.61      0.75       216\n",
      "           1       0.31      0.88      0.45        42\n",
      "\n",
      "    accuracy                           0.66       258\n",
      "   macro avg       0.63      0.75      0.60       258\n",
      "weighted avg       0.86      0.66      0.70       258\n",
      "\n",
      "0.13               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.64      0.77       216\n",
      "           1       0.32      0.86      0.46        42\n",
      "\n",
      "    accuracy                           0.68       258\n",
      "   macro avg       0.64      0.75      0.62       258\n",
      "weighted avg       0.85      0.68      0.72       258\n",
      "\n",
      "0.14               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.66      0.78       216\n",
      "           1       0.33      0.86      0.47        42\n",
      "\n",
      "    accuracy                           0.69       258\n",
      "   macro avg       0.64      0.76      0.63       258\n",
      "weighted avg       0.86      0.69      0.73       258\n",
      "\n",
      "0.15               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.67      0.79       216\n",
      "           1       0.33      0.83      0.47        42\n",
      "\n",
      "    accuracy                           0.70       258\n",
      "   macro avg       0.64      0.75      0.63       258\n",
      "weighted avg       0.85      0.70      0.74       258\n",
      "\n",
      "0.16               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.69      0.80       216\n",
      "           1       0.34      0.83      0.48        42\n",
      "\n",
      "    accuracy                           0.71       258\n",
      "   macro avg       0.65      0.76      0.64       258\n",
      "weighted avg       0.85      0.71      0.75       258\n",
      "\n",
      "0.17               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.70      0.81       216\n",
      "           1       0.35      0.83      0.49        42\n",
      "\n",
      "    accuracy                           0.72       258\n",
      "   macro avg       0.65      0.77      0.65       258\n",
      "weighted avg       0.86      0.72      0.76       258\n",
      "\n",
      "0.18               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.71      0.81       216\n",
      "           1       0.36      0.83      0.50        42\n",
      "\n",
      "    accuracy                           0.73       258\n",
      "   macro avg       0.66      0.77      0.66       258\n",
      "weighted avg       0.86      0.73      0.76       258\n",
      "\n",
      "0.19               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.72      0.82       216\n",
      "           1       0.37      0.83      0.51        42\n",
      "\n",
      "    accuracy                           0.74       258\n",
      "   macro avg       0.66      0.78      0.67       258\n",
      "weighted avg       0.86      0.74      0.77       258\n",
      "\n",
      "0.2               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.73      0.83       216\n",
      "           1       0.37      0.83      0.51        42\n",
      "\n",
      "    accuracy                           0.74       258\n",
      "   macro avg       0.66      0.78      0.67       258\n",
      "weighted avg       0.86      0.74      0.78       258\n",
      "\n",
      "0.21               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.74      0.84       216\n",
      "           1       0.38      0.83      0.53        42\n",
      "\n",
      "    accuracy                           0.76       258\n",
      "   macro avg       0.67      0.79      0.68       258\n",
      "weighted avg       0.86      0.76      0.79       258\n",
      "\n",
      "0.22               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.76      0.84       216\n",
      "           1       0.39      0.79      0.52        42\n",
      "\n",
      "    accuracy                           0.76       258\n",
      "   macro avg       0.67      0.77      0.68       258\n",
      "weighted avg       0.86      0.76      0.79       258\n",
      "\n",
      "0.23               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.78      0.85       216\n",
      "           1       0.41      0.79      0.54        42\n",
      "\n",
      "    accuracy                           0.78       258\n",
      "   macro avg       0.68      0.78      0.70       258\n",
      "weighted avg       0.86      0.78      0.80       258\n",
      "\n",
      "0.24               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.79      0.86       216\n",
      "           1       0.42      0.79      0.55        42\n",
      "\n",
      "    accuracy                           0.79       258\n",
      "   macro avg       0.69      0.79      0.71       258\n",
      "weighted avg       0.86      0.79      0.81       258\n",
      "\n",
      "0.25               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.80      0.86       216\n",
      "           1       0.42      0.74      0.53        42\n",
      "\n",
      "    accuracy                           0.79       258\n",
      "   macro avg       0.68      0.77      0.70       258\n",
      "weighted avg       0.86      0.79      0.81       258\n",
      "\n",
      "0.26               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.82      0.88       216\n",
      "           1       0.44      0.74      0.55        42\n",
      "\n",
      "    accuracy                           0.81       258\n",
      "   macro avg       0.69      0.78      0.71       258\n",
      "weighted avg       0.86      0.81      0.82       258\n",
      "\n",
      "0.27               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.89       216\n",
      "           1       0.47      0.74      0.57        42\n",
      "\n",
      "    accuracy                           0.82       258\n",
      "   macro avg       0.71      0.79      0.73       258\n",
      "weighted avg       0.87      0.82      0.84       258\n",
      "\n",
      "0.28               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.89       216\n",
      "           1       0.48      0.74      0.58        42\n",
      "\n",
      "    accuracy                           0.83       258\n",
      "   macro avg       0.71      0.79      0.73       258\n",
      "weighted avg       0.87      0.83      0.84       258\n",
      "\n",
      "0.29               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.90       216\n",
      "           1       0.49      0.74      0.59        42\n",
      "\n",
      "    accuracy                           0.83       258\n",
      "   macro avg       0.72      0.79      0.74       258\n",
      "weighted avg       0.87      0.83      0.85       258\n",
      "\n",
      "0.3               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90       216\n",
      "           1       0.49      0.71      0.58        42\n",
      "\n",
      "    accuracy                           0.83       258\n",
      "   macro avg       0.72      0.79      0.74       258\n",
      "weighted avg       0.87      0.83      0.84       258\n",
      "\n",
      "0.31               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89       216\n",
      "           1       0.48      0.69      0.57        42\n",
      "\n",
      "    accuracy                           0.83       258\n",
      "   macro avg       0.71      0.77      0.73       258\n",
      "weighted avg       0.86      0.83      0.84       258\n",
      "\n",
      "0.32               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89       216\n",
      "           1       0.48      0.69      0.57        42\n",
      "\n",
      "    accuracy                           0.83       258\n",
      "   macro avg       0.71      0.77      0.73       258\n",
      "weighted avg       0.86      0.83      0.84       258\n",
      "\n",
      "0.33               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.89       216\n",
      "           1       0.48      0.64      0.55        42\n",
      "\n",
      "    accuracy                           0.83       258\n",
      "   macro avg       0.70      0.75      0.72       258\n",
      "weighted avg       0.85      0.83      0.84       258\n",
      "\n",
      "0.34               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90       216\n",
      "           1       0.49      0.64      0.56        42\n",
      "\n",
      "    accuracy                           0.83       258\n",
      "   macro avg       0.71      0.76      0.73       258\n",
      "weighted avg       0.86      0.83      0.84       258\n",
      "\n",
      "0.35000000000000003               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90       216\n",
      "           1       0.51      0.62      0.56        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.72      0.75      0.73       258\n",
      "weighted avg       0.86      0.84      0.85       258\n",
      "\n",
      "0.36               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91       216\n",
      "           1       0.53      0.62      0.57        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.73      0.76      0.74       258\n",
      "weighted avg       0.86      0.85      0.85       258\n",
      "\n",
      "0.37               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       216\n",
      "           1       0.55      0.62      0.58        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.74      0.76      0.75       258\n",
      "weighted avg       0.86      0.86      0.86       258\n",
      "\n",
      "0.38               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91       216\n",
      "           1       0.55      0.57      0.56        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.73      0.74      0.73       258\n",
      "weighted avg       0.86      0.85      0.85       258\n",
      "\n",
      "0.39               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       216\n",
      "           1       0.55      0.55      0.55        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.73      0.73      0.73       258\n",
      "weighted avg       0.85      0.85      0.85       258\n",
      "\n",
      "0.4               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91       216\n",
      "           1       0.56      0.55      0.55        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.74      0.73      0.73       258\n",
      "weighted avg       0.86      0.86      0.86       258\n",
      "\n",
      "0.41000000000000003               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       216\n",
      "           1       0.59      0.55      0.57        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.75      0.74      0.74       258\n",
      "weighted avg       0.86      0.86      0.86       258\n",
      "\n",
      "0.42               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       216\n",
      "           1       0.59      0.52      0.56        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.75      0.73      0.74       258\n",
      "weighted avg       0.86      0.86      0.86       258\n",
      "\n",
      "0.43               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       216\n",
      "           1       0.61      0.52      0.56        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.76      0.73      0.74       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.44               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       216\n",
      "           1       0.63      0.52      0.57        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.73      0.75       258\n",
      "weighted avg       0.86      0.87      0.87       258\n",
      "\n",
      "0.45               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       216\n",
      "           1       0.69      0.52      0.59        42\n",
      "\n",
      "    accuracy                           0.88       258\n",
      "   macro avg       0.80      0.74      0.76       258\n",
      "weighted avg       0.88      0.88      0.88       258\n",
      "\n",
      "0.46               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       216\n",
      "           1       0.70      0.50      0.58        42\n",
      "\n",
      "    accuracy                           0.88       258\n",
      "   macro avg       0.80      0.73      0.76       258\n",
      "weighted avg       0.87      0.88      0.88       258\n",
      "\n",
      "0.47000000000000003               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       216\n",
      "           1       0.70      0.50      0.58        42\n",
      "\n",
      "    accuracy                           0.88       258\n",
      "   macro avg       0.80      0.73      0.76       258\n",
      "weighted avg       0.87      0.88      0.88       258\n",
      "\n",
      "0.48               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       216\n",
      "           1       0.71      0.48      0.57        42\n",
      "\n",
      "    accuracy                           0.88       258\n",
      "   macro avg       0.81      0.72      0.75       258\n",
      "weighted avg       0.87      0.88      0.87       258\n",
      "\n",
      "0.49               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       216\n",
      "           1       0.71      0.48      0.57        42\n",
      "\n",
      "    accuracy                           0.88       258\n",
      "   macro avg       0.81      0.72      0.75       258\n",
      "weighted avg       0.87      0.88      0.87       258\n",
      "\n",
      "0.5               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       216\n",
      "           1       0.71      0.48      0.57        42\n",
      "\n",
      "    accuracy                           0.88       258\n",
      "   macro avg       0.81      0.72      0.75       258\n",
      "weighted avg       0.87      0.88      0.87       258\n",
      "\n",
      "0.51               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94       216\n",
      "           1       0.74      0.48      0.58        42\n",
      "\n",
      "    accuracy                           0.89       258\n",
      "   macro avg       0.82      0.72      0.76       258\n",
      "weighted avg       0.88      0.89      0.88       258\n",
      "\n",
      "0.52               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       216\n",
      "           1       0.71      0.40      0.52        42\n",
      "\n",
      "    accuracy                           0.88       258\n",
      "   macro avg       0.80      0.69      0.72       258\n",
      "weighted avg       0.86      0.88      0.86       258\n",
      "\n",
      "0.53               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       216\n",
      "           1       0.71      0.40      0.52        42\n",
      "\n",
      "    accuracy                           0.88       258\n",
      "   macro avg       0.80      0.69      0.72       258\n",
      "weighted avg       0.86      0.88      0.86       258\n",
      "\n",
      "0.54               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.92       216\n",
      "           1       0.68      0.36      0.47        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.78      0.66      0.70       258\n",
      "weighted avg       0.85      0.87      0.85       258\n",
      "\n",
      "0.55               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.92       216\n",
      "           1       0.68      0.36      0.47        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.78      0.66      0.70       258\n",
      "weighted avg       0.85      0.87      0.85       258\n",
      "\n",
      "0.56               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.92       216\n",
      "           1       0.68      0.36      0.47        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.78      0.66      0.70       258\n",
      "weighted avg       0.85      0.87      0.85       258\n",
      "\n",
      "0.5700000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.92       216\n",
      "           1       0.68      0.36      0.47        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.78      0.66      0.70       258\n",
      "weighted avg       0.85      0.87      0.85       258\n",
      "\n",
      "0.58               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       216\n",
      "           1       0.67      0.33      0.44        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.77      0.65      0.68       258\n",
      "weighted avg       0.85      0.86      0.84       258\n",
      "\n",
      "0.59               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       216\n",
      "           1       0.68      0.31      0.43        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.78      0.64      0.67       258\n",
      "weighted avg       0.85      0.86      0.84       258\n",
      "\n",
      "0.6               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       216\n",
      "           1       0.68      0.31      0.43        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.78      0.64      0.67       258\n",
      "weighted avg       0.85      0.86      0.84       258\n",
      "\n",
      "0.61               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       216\n",
      "           1       0.68      0.31      0.43        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.78      0.64      0.67       258\n",
      "weighted avg       0.85      0.86      0.84       258\n",
      "\n",
      "0.62               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93       216\n",
      "           1       0.72      0.31      0.43        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.80      0.64      0.68       258\n",
      "weighted avg       0.85      0.87      0.85       258\n",
      "\n",
      "0.63               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.92       216\n",
      "           1       0.71      0.29      0.41        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.79      0.63      0.67       258\n",
      "weighted avg       0.85      0.86      0.84       258\n",
      "\n",
      "0.64               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.92       216\n",
      "           1       0.71      0.29      0.41        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.79      0.63      0.67       258\n",
      "weighted avg       0.85      0.86      0.84       258\n",
      "\n",
      "0.65               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       216\n",
      "           1       0.69      0.26      0.38        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.78      0.62      0.65       258\n",
      "weighted avg       0.84      0.86      0.83       258\n",
      "\n",
      "0.66               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       216\n",
      "           1       0.67      0.24      0.35        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.77      0.61      0.64       258\n",
      "weighted avg       0.84      0.86      0.83       258\n",
      "\n",
      "0.67               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       216\n",
      "           1       0.69      0.21      0.33        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.78      0.60      0.62       258\n",
      "weighted avg       0.84      0.86      0.82       258\n",
      "\n",
      "0.68               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       216\n",
      "           1       0.69      0.21      0.33        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.78      0.60      0.62       258\n",
      "weighted avg       0.84      0.86      0.82       258\n",
      "\n",
      "0.6900000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       216\n",
      "           1       0.69      0.21      0.33        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.78      0.60      0.62       258\n",
      "weighted avg       0.84      0.86      0.82       258\n",
      "\n",
      "0.7000000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       216\n",
      "           1       0.69      0.21      0.33        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.78      0.60      0.62       258\n",
      "weighted avg       0.84      0.86      0.82       258\n",
      "\n",
      "0.71               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       216\n",
      "           1       0.69      0.21      0.33        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.78      0.60      0.62       258\n",
      "weighted avg       0.84      0.86      0.82       258\n",
      "\n",
      "0.72               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92       216\n",
      "           1       0.75      0.21      0.33        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.81      0.60      0.63       258\n",
      "weighted avg       0.85      0.86      0.83       258\n",
      "\n",
      "0.73               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92       216\n",
      "           1       0.75      0.21      0.33        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.81      0.60      0.63       258\n",
      "weighted avg       0.85      0.86      0.83       258\n",
      "\n",
      "0.74               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92       216\n",
      "           1       0.75      0.21      0.33        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.81      0.60      0.63       258\n",
      "weighted avg       0.85      0.86      0.83       258\n",
      "\n",
      "0.75               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92       216\n",
      "           1       0.75      0.21      0.33        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.81      0.60      0.63       258\n",
      "weighted avg       0.85      0.86      0.83       258\n",
      "\n",
      "0.76               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92       216\n",
      "           1       0.75      0.21      0.33        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.81      0.60      0.63       258\n",
      "weighted avg       0.85      0.86      0.83       258\n",
      "\n",
      "0.77               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92       216\n",
      "           1       0.75      0.21      0.33        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.81      0.60      0.63       258\n",
      "weighted avg       0.85      0.86      0.83       258\n",
      "\n",
      "0.78               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       216\n",
      "           1       0.73      0.19      0.30        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.79      0.59      0.61       258\n",
      "weighted avg       0.84      0.86      0.82       258\n",
      "\n",
      "0.79               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       216\n",
      "           1       0.73      0.19      0.30        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.79      0.59      0.61       258\n",
      "weighted avg       0.84      0.86      0.82       258\n",
      "\n",
      "0.8               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       216\n",
      "           1       0.78      0.17      0.27        42\n",
      "\n",
      "    accuracy                           0.86       258\n",
      "   macro avg       0.82      0.58      0.60       258\n",
      "weighted avg       0.85      0.86      0.82       258\n",
      "\n",
      "0.81               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       216\n",
      "           1       0.75      0.14      0.24        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.80      0.57      0.58       258\n",
      "weighted avg       0.84      0.85      0.81       258\n",
      "\n",
      "0.8200000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.92       216\n",
      "           1       0.71      0.12      0.20        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.78      0.55      0.56       258\n",
      "weighted avg       0.83      0.85      0.80       258\n",
      "\n",
      "0.8300000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.92       216\n",
      "           1       0.71      0.12      0.20        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.78      0.55      0.56       258\n",
      "weighted avg       0.83      0.85      0.80       258\n",
      "\n",
      "0.84               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91       216\n",
      "           1       0.67      0.10      0.17        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.76      0.54      0.54       258\n",
      "weighted avg       0.82      0.84      0.79       258\n",
      "\n",
      "0.85               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91       216\n",
      "           1       0.67      0.10      0.17        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.76      0.54      0.54       258\n",
      "weighted avg       0.82      0.84      0.79       258\n",
      "\n",
      "0.86               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91       216\n",
      "           1       0.67      0.10      0.17        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.76      0.54      0.54       258\n",
      "weighted avg       0.82      0.84      0.79       258\n",
      "\n",
      "0.87               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91       216\n",
      "           1       0.67      0.10      0.17        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.76      0.54      0.54       258\n",
      "weighted avg       0.82      0.84      0.79       258\n",
      "\n",
      "0.88               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       216\n",
      "           1       0.80      0.10      0.17        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.82      0.55      0.54       258\n",
      "weighted avg       0.84      0.85      0.80       258\n",
      "\n",
      "0.89               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       216\n",
      "           1       0.80      0.10      0.17        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.82      0.55      0.54       258\n",
      "weighted avg       0.84      0.85      0.80       258\n",
      "\n",
      "0.9               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       216\n",
      "           1       0.80      0.10      0.17        42\n",
      "\n",
      "    accuracy                           0.85       258\n",
      "   macro avg       0.82      0.55      0.54       258\n",
      "weighted avg       0.84      0.85      0.80       258\n",
      "\n",
      "0.91               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.91       216\n",
      "           1       0.75      0.07      0.13        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.80      0.53      0.52       258\n",
      "weighted avg       0.83      0.84      0.79       258\n",
      "\n",
      "0.92               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.91       216\n",
      "           1       0.75      0.07      0.13        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.80      0.53      0.52       258\n",
      "weighted avg       0.83      0.84      0.79       258\n",
      "\n",
      "0.93               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.67      0.05      0.09        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.75      0.52      0.50       258\n",
      "weighted avg       0.81      0.84      0.78       258\n",
      "\n",
      "0.9400000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.67      0.05      0.09        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.75      0.52      0.50       258\n",
      "weighted avg       0.81      0.84      0.78       258\n",
      "\n",
      "0.9500000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.50      0.02      0.05        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.67      0.51      0.48       258\n",
      "weighted avg       0.78      0.84      0.77       258\n",
      "\n",
      "0.96               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.97               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.98               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n",
      "0.99               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       216\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.42      0.50      0.46       258\n",
      "weighted avg       0.70      0.84      0.76       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for threshold in np.arange(0,1,0.01):\n",
    "    predicted_proba = lgmodel.predict_proba(X_val)\n",
    "    predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "    accuracy = accuracy_score(y_val, predicted)\n",
    "    print(threshold, classification_report(y_val, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "loggrid = {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "          'C': np.logspace(-4, 4, 20),\n",
    "          'solver' : ['lbfgs', 'newton-cg' , 'liblinear', 'sag', 'saga'],\n",
    "          'max_iter': [100, 1000, 2500, 5000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(lgmodel, param_grid = loggrid, cv = 3, verbose = True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1600 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 699 tasks      | elapsed:   29.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1348 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1996 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2720 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3500 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4420 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4800 out of 4800 | elapsed:  7.9min finished\n"
     ]
    }
   ],
   "source": [
    "best_clf = clf.fit(X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.872093023255814"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.best_estimator_.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 545.5594781168514,\n",
       " 'max_iter': 100,\n",
       " 'penalty': 'l2',\n",
       " 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = best_clf.best_estimator_.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.872093023255814"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93       235\n",
      "           1       0.38      0.70      0.49        23\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.67      0.79      0.71       258\n",
      "weighted avg       0.92      0.87      0.89       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred2, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92       228\n",
      "           1       0.45      0.63      0.53        30\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.70      0.77      0.73       258\n",
      "weighted avg       0.89      0.87      0.88       258\n",
      "\n",
      "acc is 0.8682170542635659\n",
      "f1 score is 0.5277777777777778\n",
      "recall score is 0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred, y_val))\n",
    "print('acc is',metrics.accuracy_score(y_pred, y_val))\n",
    "print('f1 score is',metrics.f1_score(y_pred, y_val))\n",
    "print('recall score is',metrics.recall_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = svm.SVC(probability=True,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True, random_state=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cls.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92       228\n",
      "           1       0.45      0.63      0.53        30\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.70      0.77      0.73       258\n",
      "weighted avg       0.89      0.87      0.88       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.01               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.02               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.03               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.04               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.05               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.06               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.07               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.08               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.09               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.1               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.11               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.12               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.13               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.14               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.15               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.16               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.17               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.18               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.19               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.2               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.21               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.22               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.23               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.24               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.25               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.26               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.27               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.28               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.29               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.3               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.31               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.32               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.33               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.34               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.35000000000000003               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.36               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.37               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.38               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.39               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.4               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.41000000000000003               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.42               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.43               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.44               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.45               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.46               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.47000000000000003               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.48               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.49               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.5               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.51               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.52               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.53               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.54               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.55               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.56               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.5700000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.58               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.59               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.6               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.61               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.62               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.63               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.64               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.65               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.66               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.67               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.68               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.6900000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.7000000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.71               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.72               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.73               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.74               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.75               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.76               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.77               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.78               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.79               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.8               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.81               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.8200000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.8300000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.84               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.85               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.86               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.87               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.88               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.89               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.9               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.91               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.92               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.93               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.9400000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.9500000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.96               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.97               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.98               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.99               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       216\n",
      "           1       0.63      0.45      0.53        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.77      0.70      0.73       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for threshold in np.arange(0,1,0.01):\n",
    "    predicted_proba = cls.predict_proba(X_val)\n",
    "    predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "    accuracy = accuracy_score(y_val, y_svmpred)\n",
    "    print(threshold, classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmparams = {'kernel':('linear','poly','rbf','sigmoid'),\n",
    "            'C':[1,52,10],\n",
    "            'degree':[3,8],\n",
    "            'coef0':[0.001,10,0.5],\n",
    "            'gamma':('auto','scale')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 720 out of 720 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(probability=True, random_state=0),\n",
       "             param_grid={'C': [1, 52, 10], 'coef0': [0.001, 10, 0.5],\n",
       "                         'degree': [3, 8], 'gamma': ('auto', 'scale'),\n",
       "                         'kernel': ('linear', 'poly', 'rbf', 'sigmoid')},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsvm=GridSearchCV(cls, svmparams, cv=5, verbose=1)\n",
    "gridsvm.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 52, 'coef0': 0.001, 'degree': 3, 'gamma': 'auto', 'kernel': 'linear'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsvm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_svmpred = gridsvm.best_estimator_.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.93       233\n",
      "           1       0.40      0.68      0.51        25\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.68      0.79      0.72       258\n",
      "weighted avg       0.91      0.87      0.89       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_svmpred, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.01               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.02               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.03               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.04               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.05               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.06               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.07               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.08               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.09               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.1               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.11               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.12               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.13               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.14               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.15               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.16               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.17               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.18               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.19               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.2               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.21               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.22               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.23               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.24               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.25               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.26               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.27               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.28               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.29               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.3               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.31               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.32               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.33               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.34               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.35000000000000003               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.36               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.37               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.38               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.39               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.4               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.41000000000000003               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.42               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.43               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.44               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.45               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.46               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.47000000000000003               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.48               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.49               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.5               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.51               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.52               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.53               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.54               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.55               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.56               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.5700000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.58               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.59               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.6               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.61               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.62               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.63               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.64               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.65               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.66               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.67               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.68               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.6900000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.7000000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.71               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.72               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.73               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.74               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.75               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.76               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.77               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.78               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.79               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.8               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.81               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.8200000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.8300000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.84               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.85               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.86               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.87               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.88               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.89               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.9               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.91               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.92               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.93               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.9400000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.9500000000000001               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.96               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.97               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.98               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n",
      "0.99               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       216\n",
      "           1       0.68      0.40      0.51        42\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.79      0.68      0.72       258\n",
      "weighted avg       0.86      0.87      0.86       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for threshold in np.arange(0,1,0.01):\n",
    "    predicted_proba = gridsvm.best_estimator_.predict_proba(X_val)\n",
    "    predicted = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "    accuracy = accuracy_score(y_val, y_svmpred)\n",
    "    print(threshold, classification_report(y_val, y_svmpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting ROC and comparing AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_fpr, logistic_tpr, threshold1 = roc_curve(y_val, y_predlog)\n",
    "auc_logistic = auc(logistic_fpr, logistic_tpr)\n",
    "\n",
    "logistic_fpr2, logistic_tpr2, threshold12 = roc_curve(y_val, y_pred2)\n",
    "auc_logistic2 = auc(logistic_fpr2, logistic_tpr2)\n",
    "\n",
    "\n",
    "svm_fpr, svm_tpr, threshold2 = roc_curve(y_val, y_svmpred)\n",
    "auc_svm = auc(svm_fpr, svm_tpr)\n",
    "\n",
    "svm_fpr2, svm_tpr2, threshold22 = roc_curve(y_val, y_pred)\n",
    "auc_svm2 = auc(svm_fpr2, svm_tpr2)\n",
    "\n",
    "randfor_fpr, randfor_tpr, threshold3 = roc_curve(y_val, y_predrandf)\n",
    "auc_randfor = auc(randfor_fpr, randfor_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5), dpi=100)\n",
    "plt.plot(svm_fpr, svm_tpr, linestyle='-', label='SVM (auc = %0.3f)' % auc_svm)\n",
    "plt.plot(logistic_fpr, logistic_tpr, marker='.', label='Logistic (auc = %0.3f)' % auc_logistic)\n",
    "plt.plot(randfor_fpr, randfor_tpr, marker='*', label='Random Forest (auc = %0.3f)' % auc_randfor)\n",
    "plt.plot(svm_fpr2, svm_tpr2, linestyle='--', label='SVM2 (auc = %0.3f)' % auc_svm)\n",
    "plt.plot(logistic_fpr2, logistic_tpr2, marker='', label='Logistic2 (auc = %0.3f)' % auc_logistic)\n",
    "\n",
    "\n",
    "plt.xlabel('False Positive Rate -->')\n",
    "plt.ylabel('True Positive Rate -->')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold value is: 1\n"
     ]
    }
   ],
   "source": [
    "optimal_idx = np.argmax(logistic_tpr - logistic_fpr)\n",
    "optimal_threshold = threshold1[optimal_idx]\n",
    "print(\"Threshold value is:\", optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.47619048, 1.        ])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.03703704, 1.        ])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.43915344, 0.        ])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_tpr - logistic_fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2467801210527797e-05"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_probas_0, y_pred_probas_1 = cross_val_predict(lgmodel,\n",
    "                                                     X_val, y_val, \n",
    "                                                     cv=5,\n",
    "                                                     method = 'predict_proba').T\n",
    "# Generate precision and thresholds (and recalls) using probabilities for class 1\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, y_pred_probas_1)\n",
    "# Populate dataframe with precision and threshold\n",
    "df_recall = pd.DataFrame({\"recall\" : recall[:-1],\n",
    "                          \"threshold\" : thresholds})\n",
    "\n",
    "\n",
    "\n",
    "# Find out which threshold guarantees a recall of 0.9\n",
    "threshold = df_precision[df_precision['recall'] >= 0.89]['threshold'].min()\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.000359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.000393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.841408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.845611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.915442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.943117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.984383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       recall  threshold\n",
       "0    1.000000   0.000012\n",
       "1    0.976190   0.000096\n",
       "2    0.976190   0.000250\n",
       "3    0.976190   0.000359\n",
       "4    0.976190   0.000393\n",
       "..        ...        ...\n",
       "253  0.119048   0.841408\n",
       "254  0.095238   0.845611\n",
       "255  0.071429   0.915442\n",
       "256  0.047619   0.943117\n",
       "257  0.023810   0.984383\n",
       "\n",
       "[258 rows x 2 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_recall' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-aa0ebf6cd56a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_recall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_recall' is not defined"
     ]
    }
   ],
   "source": [
    "df_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
